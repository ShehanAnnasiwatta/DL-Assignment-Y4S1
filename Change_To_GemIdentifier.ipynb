{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ShehanAnnasiwatta/DL-Assignment-Y4S1/blob/Harith_CNN/Change_To_GemIdentifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NfxlJcXe8LpI"
   },
   "outputs": [],
   "source": [
    "! pip install numpy pandas matplotlib tensorflow opendatasets -q\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import opendatasets as od"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VHg4xoAO9-do",
    "outputId": "c087a983-154b-4847-d8eb-0b14c40c6fbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \".\\gemstones-images\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "od.download(\"https://www.kaggle.com/datasets/lsind18/gemstones-images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Jqf6gd4q-m9z"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE =(256,256)\n",
    "\n",
    "train_data_dir = \"C:\\\\Users\\\\Harith Rajapaksha\\\\Desktop\\\\Dl-Assignment\\\\gemstones-images\\\\test\"\n",
    "test_data_dir = \"C:\\\\Users\\\\Harith Rajapaksha\\\\Desktop\\\\Dl-Assignment\\\\gemstones-images\\\\train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eto53PbM_Ppb",
    "outputId": "e8a8a90a-edb0-4312-f1b2-f3a47060eb28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 363 files belonging to 87 classes.\n",
      "Using 327 files for training.\n",
      "Found 363 files belonging to 87 classes.\n",
      "Using 36 files for validation.\n",
      "Found 2856 files belonging to 87 classes.\n",
      "Train Data: <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n",
      "Validation Data: <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "train_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_data_dir,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    subset='training',\n",
    "    validation_split=0.1,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "validation_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_data_dir,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    subset='validation',\n",
    "    validation_split=0.1,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_data = tf.keras.utils.image_dataset_from_directory(test_data_dir,\n",
    "                                                         batch_size=BATCH_SIZE,\n",
    "                                                         image_size=IMAGE_SIZE)\n",
    "\n",
    "class_names=train_data.class_names\n",
    "class_names\n",
    "\n",
    "# Print shapes to verify loading\n",
    "print(\"Train Data:\", train_data)\n",
    "print(\"Validation Data:\", validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ra2Aj5tTBt97",
    "outputId": "78919be9-1b7a-40fa-bc0c-04473a73887a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 256, 256, 3)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "for image_batch,label_batch in train_data.take(1):\n",
    "   print(image_batch.shape)\n",
    "   print(label_batch .shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B392B2m6Cbpd",
    "outputId": "49a21a58-0782-41d3-bdec-d7844952c02f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n",
      "Validation Data: <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "train_data=train_data.map(lambda x,y:(x/255.0,y))\n",
    "validation_data=validation_data.map(lambda x,y:(x/255.0,y))\n",
    "test_data=test_data.map(lambda x,y:(x/255.0,y))\n",
    "\n",
    "# Cache and Prefetch\n",
    "train_data = train_data.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "validation_data = validation_data.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Print shapes to verify loading\n",
    "print(\"Train Data:\", train_data)\n",
    "print(\"Validation Data:\", validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lraW1PC3Ep23"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harith Rajapaksha\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\preprocessing\\tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "data_augmentation = tf.keras.Sequential(\n",
    "  [\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\",input_shape=(256,256,3)),\n",
    "    tf.keras.layers.RandomRotation(0.2),\n",
    "    tf.keras.layers.RandomZoom(0.2),\n",
    "  ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HjaVikWwFVQ3",
    "outputId": "baf8d8be-58db-4741-a88c-303cc1378fbb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harith Rajapaksha\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n",
      "Validation Data: <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Start to create the model\n",
    "model = tf.keras.models.Sequential()  # Create the model as Sequential\n",
    "\n",
    "\n",
    "# Adding the conventional layers\n",
    "model.add(tf.keras.layers.Conv2D(256, (3, 3), activation='relu', input_shape=(256,256, 3)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D())\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D())\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D())\n",
    "\n",
    "# Flatten layer\n",
    "model.add(tf.keras.layers.Flatten())  # Flatten the input\n",
    "\n",
    "# Adding dropout after flattening\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "# Batch normalization after flattening\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))  # Dense layer with 128 neurons\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))  # Dense layer with 128 neurons\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))    # Dense layer with 32 neurons\n",
    "\n",
    "model.add(tf.keras.layers.Dense(87, activation='softmax'))\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Use a smaller learning rate\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "\n",
    "# Compile the model (add this step)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',  # Correct loss function for integer-encoded labels\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Check the datasets\n",
    "print(\"Train Data:\", train_data)\n",
    "print(\"Validation Data:\", validation_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G8AWjpMlIe3J",
    "outputId": "75f48874-d480-43f7-8751-03343577042d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 13s/step - accuracy: 0.0091 - loss: 6.5221 - val_accuracy: 0.0556 - val_loss: 5.3054\n",
      "Epoch 2/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 13s/step - accuracy: 0.0294 - loss: 5.7480 - val_accuracy: 0.0278 - val_loss: 4.5064\n",
      "Epoch 3/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 13s/step - accuracy: 0.0439 - loss: 4.5156 - val_accuracy: 0.0000e+00 - val_loss: 4.4740\n",
      "Epoch 4/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 12s/step - accuracy: 0.1109 - loss: 3.9725 - val_accuracy: 0.0000e+00 - val_loss: 4.7658\n",
      "Epoch 5/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 17s/step - accuracy: 0.1662 - loss: 3.4771 - val_accuracy: 0.0278 - val_loss: 5.4423\n",
      "Epoch 6/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 13s/step - accuracy: 0.2755 - loss: 3.1084 - val_accuracy: 0.0000e+00 - val_loss: 5.1605\n",
      "Epoch 7/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 13s/step - accuracy: 0.3505 - loss: 2.7290 - val_accuracy: 0.0000e+00 - val_loss: 6.0949\n",
      "Epoch 8/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 17s/step - accuracy: 0.4012 - loss: 2.4547 - val_accuracy: 0.0000e+00 - val_loss: 8.3190\n",
      "Epoch 9/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 13s/step - accuracy: 0.4411 - loss: 2.3867 - val_accuracy: 0.0000e+00 - val_loss: 10.0595\n",
      "Epoch 10/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 13s/step - accuracy: 0.4483 - loss: 2.1154 - val_accuracy: 0.0000e+00 - val_loss: 7.7510\n",
      "Epoch 11/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 13s/step - accuracy: 0.5469 - loss: 1.8863 - val_accuracy: 0.0278 - val_loss: 8.1888\n",
      "Epoch 12/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 13s/step - accuracy: 0.5968 - loss: 1.7585 - val_accuracy: 0.0000e+00 - val_loss: 10.3369\n",
      "Epoch 13/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 13s/step - accuracy: 0.6416 - loss: 1.5595 - val_accuracy: 0.0000e+00 - val_loss: 12.0568\n",
      "Epoch 14/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 13s/step - accuracy: 0.6193 - loss: 1.5668 - val_accuracy: 0.0278 - val_loss: 11.7552\n",
      "Epoch 15/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 13s/step - accuracy: 0.6796 - loss: 1.3173 - val_accuracy: 0.0000e+00 - val_loss: 13.8754\n",
      "Epoch 16/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 13s/step - accuracy: 0.6715 - loss: 1.2595 - val_accuracy: 0.0000e+00 - val_loss: 15.2626\n",
      "Epoch 17/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 14s/step - accuracy: 0.7256 - loss: 1.1067 - val_accuracy: 0.0278 - val_loss: 13.8837\n",
      "Epoch 18/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 13s/step - accuracy: 0.7718 - loss: 0.9698 - val_accuracy: 0.0278 - val_loss: 15.9653\n",
      "Epoch 19/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 18s/step - accuracy: 0.7627 - loss: 0.8881 - val_accuracy: 0.0278 - val_loss: 14.7152\n",
      "Epoch 20/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 14s/step - accuracy: 0.7935 - loss: 0.9126 - val_accuracy: 0.0000e+00 - val_loss: 15.8297\n",
      "Epoch 21/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 13s/step - accuracy: 0.7885 - loss: 0.8811 - val_accuracy: 0.0000e+00 - val_loss: 13.5308\n",
      "Epoch 22/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 14s/step - accuracy: 0.7785 - loss: 0.9462 - val_accuracy: 0.0000e+00 - val_loss: 13.4317\n",
      "Epoch 23/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 14s/step - accuracy: 0.7863 - loss: 0.9220 - val_accuracy: 0.0000e+00 - val_loss: 12.3617\n",
      "Epoch 24/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 14s/step - accuracy: 0.7893 - loss: 0.8440 - val_accuracy: 0.0000e+00 - val_loss: 14.2652\n",
      "Epoch 25/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 13s/step - accuracy: 0.7942 - loss: 0.7644 - val_accuracy: 0.0000e+00 - val_loss: 17.2015\n",
      "Epoch 26/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 13s/step - accuracy: 0.8171 - loss: 0.7187 - val_accuracy: 0.0000e+00 - val_loss: 16.1747\n",
      "Epoch 27/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 13s/step - accuracy: 0.8262 - loss: 0.7136 - val_accuracy: 0.0000e+00 - val_loss: 17.8468\n",
      "Epoch 28/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 13s/step - accuracy: 0.8157 - loss: 0.7312 - val_accuracy: 0.0278 - val_loss: 14.5016\n",
      "Epoch 29/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 14s/step - accuracy: 0.8365 - loss: 0.7727 - val_accuracy: 0.0278 - val_loss: 15.2117\n",
      "Epoch 30/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 13s/step - accuracy: 0.8602 - loss: 0.6291 - val_accuracy: 0.0000e+00 - val_loss: 14.7095\n",
      "Epoch 31/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 13s/step - accuracy: 0.8248 - loss: 0.5782 - val_accuracy: 0.0278 - val_loss: 17.3810\n",
      "Epoch 32/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 13s/step - accuracy: 0.8390 - loss: 0.6835 - val_accuracy: 0.0000e+00 - val_loss: 14.0687\n",
      "Epoch 33/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 14s/step - accuracy: 0.8387 - loss: 0.6081 - val_accuracy: 0.0000e+00 - val_loss: 17.7570\n",
      "Epoch 34/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 13s/step - accuracy: 0.8222 - loss: 0.6922 - val_accuracy: 0.0000e+00 - val_loss: 13.4994\n",
      "Epoch 35/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 13s/step - accuracy: 0.7971 - loss: 0.7576 - val_accuracy: 0.0278 - val_loss: 12.9312\n",
      "Epoch 36/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 13s/step - accuracy: 0.8047 - loss: 0.8475 - val_accuracy: 0.0278 - val_loss: 14.0046\n",
      "Epoch 37/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 13s/step - accuracy: 0.7648 - loss: 0.8320 - val_accuracy: 0.0278 - val_loss: 11.8009\n",
      "Epoch 38/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 13s/step - accuracy: 0.7913 - loss: 0.8029 - val_accuracy: 0.0000e+00 - val_loss: 14.2519\n",
      "Epoch 39/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 22s/step - accuracy: 0.7364 - loss: 1.1575 - val_accuracy: 0.0556 - val_loss: 9.5917\n",
      "Epoch 40/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 13s/step - accuracy: 0.7630 - loss: 0.9643 - val_accuracy: 0.0278 - val_loss: 14.8875\n",
      "Epoch 41/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 13s/step - accuracy: 0.8020 - loss: 0.8095 - val_accuracy: 0.0278 - val_loss: 15.7564\n",
      "Epoch 42/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 12s/step - accuracy: 0.7530 - loss: 1.1520 - val_accuracy: 0.0278 - val_loss: 12.4838\n",
      "Epoch 43/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 13s/step - accuracy: 0.7737 - loss: 0.9909 - val_accuracy: 0.0278 - val_loss: 13.5233\n",
      "Epoch 44/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 12s/step - accuracy: 0.7983 - loss: 0.8003 - val_accuracy: 0.0833 - val_loss: 10.9012\n",
      "Epoch 45/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 12s/step - accuracy: 0.8305 - loss: 0.6952 - val_accuracy: 0.0556 - val_loss: 10.1441\n",
      "Epoch 46/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 13s/step - accuracy: 0.8753 - loss: 0.4701 - val_accuracy: 0.0556 - val_loss: 13.0624\n",
      "Epoch 47/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 13s/step - accuracy: 0.8961 - loss: 0.3515 - val_accuracy: 0.0833 - val_loss: 11.2373\n",
      "Epoch 48/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 13s/step - accuracy: 0.9056 - loss: 0.3141 - val_accuracy: 0.0833 - val_loss: 10.2953\n",
      "Epoch 49/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 13s/step - accuracy: 0.9111 - loss: 0.3242 - val_accuracy: 0.0833 - val_loss: 12.4647\n",
      "Epoch 50/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18s/step - accuracy: 0.8972 - loss: 0.3591 "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=50,\n",
    "    validation_data=validation_data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_yaGAh9-zjR"
   },
   "outputs": [],
   "source": [
    "#Add the performance matrices\n",
    "\n",
    "# Use CategoricalAccuracy for multi-class classification with one-hot encoded labels\n",
    "accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "# Precision and Recall can be used, but they are typically applied on a per-class basis\n",
    "precision = tf.keras.metrics.Precision()\n",
    "recall = tf.keras.metrics.Recall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T47c_CQv_4f7"
   },
   "outputs": [],
   "source": [
    "for batch in test_data.as_numpy_iterator():\n",
    "    x, y = batch\n",
    "    # Predict the probability distribution for each class\n",
    "    yhat = model.predict(x)\n",
    "\n",
    "    # Convert predicted probabilities to class labels using argmax\n",
    "    yhat_class = np.argmax(yhat, axis=1)\n",
    "\n",
    "    # Update metrics using the true labels and predicted class labels\n",
    "    precision.update_state(y, yhat_class)\n",
    "    recall.update_state(y, yhat_class)\n",
    "    accuracy.update_state(y, yhat_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBtkOM8r9Fz7"
   },
   "outputs": [],
   "source": [
    "#Use the transfer learning\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# Load pre-trained VGG16 model + higher-level layers\n",
    "base_model = VGG16(input_shape=(256, 256, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "# Freeze the base model layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create a new model on top of it\n",
    "model = tf.keras.models.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_data,\n",
    "                    epochs=20,\n",
    "                    validation_data=validation_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kVp_ENwbA7OV"
   },
   "outputs": [],
   "source": [
    "#Use opencv to read the image\n",
    "! pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TJ2CQHUnDRmD"
   },
   "outputs": [],
   "source": [
    "#Import the open cv\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r4K8Tvt2DZos"
   },
   "outputs": [],
   "source": [
    "image=cv2.imread('/content/images (1).jpg')\n",
    "plt.imshow(image)  #Show the testing image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0lQWgC7KD12c"
   },
   "outputs": [],
   "source": [
    "#create the image resize\n",
    "resized_image=tf.image.resize(image,IMAGE_SIZE)\n",
    "scaled_image=resized_image/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oDZv6VzcEUeH"
   },
   "outputs": [],
   "source": [
    "#Create image as (1,128,128,3)\n",
    "np.expand_dims(scaled_image,0).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EcmTIuQAEvUr"
   },
   "outputs": [],
   "source": [
    "#Expand the dimensions\n",
    "\n",
    "# Assuming y_hat is the output from a softmax layer (for multi-class classification)\n",
    "y_hat = model.predict(np.expand_dims(scaled_image, 0))\n",
    "\n",
    "# Get the index of the class with the highest probability\n",
    "predicted_class_index = np.argmax(y_hat, axis=-1)\n",
    "\n",
    "# Print the relevant class name based on the predicted index\n",
    "print(f'Predicted class: {class_names[predicted_class_index[0]]}')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
